{
 "cells": [
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "import json\n",
    "import os\n",
    "\n",
    "import pandas as pd\n",
    "import pytorch_lightning as pl\n",
    "import timm\n",
    "import torch\n",
    "import wandb\n",
    "from PIL import Image\n",
    "from pytorch_lightning.callbacks import ModelCheckpoint\n",
    "from pytorch_lightning.loggers import WandbLogger\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from torch import nn\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchvision import transforms"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "torch.use_deterministic_algorithms(True)",
   "id": "fb5d5243d18b2fed",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "DEBUG = False",
   "id": "8a385e25a97e7c16",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "CONFIG_JSON_PATH = \"../../config/config.json\"\n",
    "\n",
    "with open(CONFIG_JSON_PATH) as f:\n",
    "    cfg = json.load(f)\n",
    "\n",
    "cfg[\"params\"][\"model_name\"] = \"seresnext50_32x4d.racm_in1k\"\n",
    "\n",
    "LABEL_TRAIN_PATH = cfg[\"dataset\"][\"label_train\"]\n",
    "TRAIN_CROP_DATASET_DIR = cfg[\"dataset\"][\"train_crop\"]\n",
    "\n",
    "MODEL_NAME = cfg[\"params\"][\"model_name\"]\n",
    "BATCH_SIZE = cfg[\"params\"][\"batch_size\"]\n",
    "NUM_WORKERS = cfg[\"params\"][\"num_workers\"]\n",
    "IMG_SIZE = cfg[\"params\"][\"img_size\"]\n",
    "TEST_SIZE = cfg[\"params\"][\"test_size\"]\n",
    "SEED = 2027\n",
    "LEARNING_RATE = cfg[\"params\"][\"learning_rate\"]\n",
    "\n",
    "MAX_EPOCH = 20\n",
    "\n",
    "N_SPLITS = 5"
   ],
   "id": "6819344a1688536",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "cfg",
   "id": "7eaa4c4e6edd63c2",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "pl.seed_everything(SEED, workers=True)",
   "id": "db20a53cee24bfff",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "df = pd.read_csv(LABEL_TRAIN_PATH)\n",
    "df.head()"
   ],
   "id": "75b7a971b26c852d",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### dataset",
   "id": "2e47412eed107355"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "class PupilCSV(Dataset):\n",
    "    def __init__(self, df: pd.DataFrame, transform=None):\n",
    "        self.df = df.reset_index(drop=True)\n",
    "        self.df['age_normalized'] = (self.df['age'] - self.df['age'].min()) / (\n",
    "                self.df['age'].max() - self.df['age'].min())\n",
    "        self.df['AC_normalized'] = (self.df['AC'] - self.df['AC'].min()) / (self.df['AC'].max() - self.df['AC'].min())\n",
    "        self.df['SBP_normalized'] = (self.df['SBP'] - self.df['SBP'].min()) / (\n",
    "                self.df['SBP'].max() - self.df['SBP'].min())\n",
    "        self.df['DBP_normalized'] = (self.df['DBP'] - self.df['DBP'].min()) / (\n",
    "                self.df['DBP'].max() - self.df['DBP'].min())\n",
    "        self.df['HDLC_normalized'] = (self.df['HDLC'] - self.df['HDLC'].min()) / (\n",
    "                self.df['HDLC'].max() - self.df['HDLC'].min())\n",
    "        self.df['TG_normalized'] = (self.df['TG'] - self.df['TG'].min()) / (self.df['TG'].max() - self.df['TG'].min())\n",
    "        self.df['BS_normalized'] = (self.df['BS'] - self.df['BS'].min()) / (self.df['BS'].max() - self.df['BS'].min())\n",
    "        self.transform = transform\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.df)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        img_path = self.df.loc[idx, 'path']\n",
    "        label = self.df.loc[idx, 'METS']\n",
    "        age = self.df.loc[idx, 'age_normalized']\n",
    "        ac = self.df.loc[idx, 'AC_normalized']\n",
    "        sbp = self.df.loc[idx, 'SBP_normalized']\n",
    "        dbp = self.df.loc[idx, 'DBP_normalized']\n",
    "        hdlc = self.df.loc[idx, 'HDLC_normalized']\n",
    "        tg = self.df.loc[idx, 'TG_normalized']\n",
    "        bs = self.df.loc[idx, 'BS_normalized']\n",
    "\n",
    "        image = Image.open(img_path).convert('RGB')\n",
    "\n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "\n",
    "        label = torch.tensor(label, dtype=torch.long)\n",
    "        age = torch.tensor(age, dtype=torch.float)\n",
    "        ac = torch.tensor(ac, dtype=torch.float)\n",
    "        sbp = torch.tensor(sbp, dtype=torch.float)\n",
    "        dbp = torch.tensor(dbp, dtype=torch.float)\n",
    "        hdlc = torch.tensor(hdlc, dtype=torch.float)\n",
    "        tg = torch.tensor(tg, dtype=torch.float)\n",
    "        bs = torch.tensor(bs, dtype=torch.float)\n",
    "\n",
    "        return image, label, age, ac, sbp, dbp, hdlc, tg, bs"
   ],
   "id": "1d7b75b569fd75f8",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "class PupilTestCSV(Dataset):\n",
    "    def __init__(self, df: pd.DataFrame, transform=None):\n",
    "        self.df = df.reset_index(drop=True)\n",
    "        self.transform = transform\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.df)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        img_path = self.df.loc[idx, 'path']\n",
    "        label = self.df.loc[idx, 'METS']\n",
    "\n",
    "        image = Image.open(img_path).convert('RGB')\n",
    "\n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "\n",
    "        label = torch.tensor(label, dtype=torch.long)\n",
    "\n",
    "        return image, label"
   ],
   "id": "de303f74b3e48d15",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Dataloader",
   "id": "56ae0a79c465a755"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "class PupilDataModule(pl.LightningDataModule):\n",
    "    def __init__(\n",
    "            self,\n",
    "            train_df,\n",
    "            val_df,\n",
    "            test_df,\n",
    "            batch_size: int = 32,\n",
    "            num_workers: int = 4,\n",
    "            img_size: int = 224,\n",
    "    ):\n",
    "        super().__init__()\n",
    "        self.train_df = train_df\n",
    "        self.val_df = val_df\n",
    "        self.test_df = test_df\n",
    "        self.batch_size = batch_size\n",
    "        self.num_workers = num_workers\n",
    "        self.img_size = img_size\n",
    "\n",
    "        self.train_transforms = transforms.Compose([\n",
    "            transforms.Resize((self.img_size, self.img_size)),\n",
    "\n",
    "            transforms.RandomHorizontalFlip(p=0.5),\n",
    "            transforms.RandomVerticalFlip(p=0.5),\n",
    "\n",
    "            transforms.RandomRotation(degrees=45),\n",
    "\n",
    "            transforms.RandomAffine(\n",
    "                degrees=0,\n",
    "                translate=(0.1, 0.1),\n",
    "                scale=(0.9, 1.1),\n",
    "                shear=10,\n",
    "            ),\n",
    "\n",
    "            transforms.ColorJitter(\n",
    "                brightness=0.4,\n",
    "                contrast=0.4,\n",
    "                saturation=0.4,\n",
    "                hue=0.1\n",
    "            ),\n",
    "\n",
    "            transforms.RandomPerspective(\n",
    "                distortion_scale=0.5,\n",
    "                p=0.5,\n",
    "                fill=0\n",
    "            ),\n",
    "\n",
    "            transforms.ToTensor(),\n",
    "\n",
    "            transforms.Normalize(\n",
    "                mean=[0.485, 0.456, 0.406],\n",
    "                std=[0.229, 0.224, 0.225]\n",
    "            ),\n",
    "\n",
    "            transforms.RandomErasing(\n",
    "                p=0.5,\n",
    "                scale=(0.02, 0.33),\n",
    "                ratio=(0.3, 3.3),\n",
    "                value='random'\n",
    "            ),\n",
    "        ])\n",
    "\n",
    "        self.val_transforms = transforms.Compose([\n",
    "            transforms.Resize((self.img_size, self.img_size)),\n",
    "            transforms.ToTensor(),\n",
    "            transforms.Normalize(\n",
    "                mean=[0.485, 0.456, 0.406],\n",
    "                std=[0.229, 0.224, 0.225]\n",
    "            ),\n",
    "        ])\n",
    "\n",
    "    def prepare_data(self):\n",
    "        pass\n",
    "\n",
    "    def setup(self, stage=None):\n",
    "        self.train_dataset = PupilCSV(\n",
    "            self.train_df,\n",
    "            transform=self.train_transforms\n",
    "        )\n",
    "\n",
    "        self.val_dataset = PupilCSV(\n",
    "            self.val_df,\n",
    "            transform=self.val_transforms\n",
    "        )\n",
    "\n",
    "        if self.test_df:\n",
    "            self.test_dataset = PupilTestCSV(\n",
    "                self.test_df,\n",
    "                transform=self.val_transforms,\n",
    "            )\n",
    "\n",
    "    def train_dataloader(self):\n",
    "        return DataLoader(\n",
    "            self.train_dataset,\n",
    "            batch_size=self.batch_size,\n",
    "            shuffle=True,\n",
    "            num_workers=self.num_workers,\n",
    "            pin_memory=True\n",
    "        )\n",
    "\n",
    "    def val_dataloader(self):\n",
    "        return DataLoader(\n",
    "            self.val_dataset,\n",
    "            batch_size=self.batch_size,\n",
    "            shuffle=False,\n",
    "            num_workers=self.num_workers,\n",
    "            pin_memory=True\n",
    "        )\n",
    "\n",
    "    def test_dataloader(self):\n",
    "        return DataLoader(\n",
    "            self.test_dataset,\n",
    "            batch_size=self.batch_size,\n",
    "            shuffle=False,\n",
    "            num_workers=self.num_workers,\n",
    "            pin_memory=True\n",
    "        )"
   ],
   "id": "96954b50c69d101e",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### model",
   "id": "7b0d3053626ed3a2"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "class PupilModel(pl.LightningModule):\n",
    "    def __init__(\n",
    "            self,\n",
    "            model_name: str = MODEL_NAME,\n",
    "            pretrained: bool = True,\n",
    "            num_classes: int = 2,\n",
    "            learning_rate: float = 1e-3,\n",
    "    ):\n",
    "        super().__init__()\n",
    "        self.save_hyperparameters()\n",
    "\n",
    "        self.model = timm.create_model(\n",
    "            model_name,\n",
    "            pretrained=pretrained,\n",
    "            num_classes=num_classes\n",
    "        )\n",
    "\n",
    "        self.criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "        self.aux_criterion = nn.L1Loss()\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.model(x)\n",
    "\n",
    "    def training_step(self, batch, batch_idx):\n",
    "        x, y, age, ac, sbp, dbp, hdlc, tg, bs = batch\n",
    "        logits = self(x)\n",
    "        logits_for_y, logits_for_age, logits_for_ac, logits_for_sbp, logits_for_dbp, logits_for_hdlc, logits_for_tg, logits_for_bs = torch.split(\n",
    "            logits, [2, 1, 1, 1, 1, 1, 1, 1], dim=1)\n",
    "        loss_y = self.criterion(logits_for_y, y)\n",
    "\n",
    "        logits_for_age = logits_for_age.squeeze()\n",
    "        loss_age = self.aux_criterion(logits_for_age, age)\n",
    "\n",
    "        logits_for_ac = logits_for_ac.squeeze()\n",
    "        loss_ac = self.aux_criterion(logits_for_ac, ac)\n",
    "\n",
    "        logits_for_sbp = logits_for_sbp.squeeze()\n",
    "        loss_sbp = self.aux_criterion(logits_for_sbp, sbp)\n",
    "\n",
    "        logits_for_dbp = logits_for_dbp.squeeze()\n",
    "        loss_dbp = self.aux_criterion(logits_for_dbp, dbp)\n",
    "\n",
    "        logits_for_hdlc = logits_for_hdlc.squeeze()\n",
    "        loss_hdlc = self.aux_criterion(logits_for_hdlc, hdlc)\n",
    "\n",
    "        logits_for_tg = logits_for_tg.squeeze()\n",
    "        loss_tg = self.aux_criterion(logits_for_tg, tg)\n",
    "\n",
    "        logits_for_bs = logits_for_bs.squeeze()\n",
    "        loss_bs = self.aux_criterion(logits_for_bs, bs)\n",
    "\n",
    "        total_loss = (loss_y + loss_age + loss_ac + loss_sbp + loss_dbp + loss_hdlc + loss_tg + loss_bs)\n",
    "\n",
    "        preds = torch.argmax(logits_for_y, dim=1)\n",
    "        acc = (preds == y).float().mean()\n",
    "        self.log('train_loss', total_loss, on_step=False, on_epoch=True)\n",
    "        self.log('train_acc', acc, on_step=False, on_epoch=True, prog_bar=True)\n",
    "        return total_loss\n",
    "\n",
    "    def validation_step(self, batch, batch_idx):\n",
    "        x, y, age, ac, sbp, dbp, hdlc, tg, bs = batch\n",
    "        logits = self(x)\n",
    "        logits_for_y, logits_for_age, logits_for_ac, logits_for_sbp, logits_for_dbp, logits_for_hdlc, logits_for_tg, logits_for_bs = torch.split(\n",
    "            logits, [2, 1, 1, 1, 1, 1, 1, 1], dim=1)\n",
    "        loss_y = self.criterion(logits_for_y, y)\n",
    "\n",
    "        logits_for_age = logits_for_age.squeeze()\n",
    "        loss_age = self.aux_criterion(logits_for_age, age)\n",
    "\n",
    "        logits_for_ac = logits_for_ac.squeeze()\n",
    "        loss_ac = self.aux_criterion(logits_for_ac, ac)\n",
    "\n",
    "        logits_for_sbp = logits_for_sbp.squeeze()\n",
    "        loss_sbp = self.aux_criterion(logits_for_sbp, sbp)\n",
    "\n",
    "        logits_for_dbp = logits_for_dbp.squeeze()\n",
    "        loss_dbp = self.aux_criterion(logits_for_dbp, dbp)\n",
    "\n",
    "        logits_for_hdlc = logits_for_hdlc.squeeze()\n",
    "        loss_hdlc = self.aux_criterion(logits_for_hdlc, hdlc)\n",
    "\n",
    "        logits_for_tg = logits_for_tg.squeeze()\n",
    "        loss_tg = self.aux_criterion(logits_for_tg, tg)\n",
    "\n",
    "        logits_for_bs = logits_for_bs.squeeze()\n",
    "        loss_bs = self.aux_criterion(logits_for_bs, bs)\n",
    "\n",
    "        total_loss = (loss_y + loss_age + loss_ac + loss_sbp + loss_dbp + loss_hdlc + loss_tg + loss_bs)\n",
    "\n",
    "        preds = torch.argmax(logits_for_y, dim=1)\n",
    "        acc = (preds == y).float().mean()\n",
    "        self.log('val_loss', total_loss, on_step=False, on_epoch=True)\n",
    "        self.log('val_acc', acc, on_step=False, on_epoch=True, prog_bar=True)\n",
    "\n",
    "    def test_step(self, batch, batch_idx):\n",
    "        x, y, age, ac, sbp, dbp, hdlc, tg, bs = batch\n",
    "        logits = self(x)\n",
    "        loss = self.criterion(logits, y)\n",
    "        preds = torch.argmax(logits, dim=1)\n",
    "        acc = (preds == y).float().mean()\n",
    "        self.log('test_loss', loss, on_step=False, on_epoch=True)\n",
    "        self.log('test_acc', acc, on_step=False, on_epoch=True, prog_bar=True)\n",
    "\n",
    "    def configure_optimizers(self):\n",
    "        optimizer = torch.optim.AdamW(self.parameters(), lr=self.hparams.learning_rate)\n",
    "        scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(optimizer, T_max=MAX_EPOCH)\n",
    "        return [optimizer], [scheduler]"
   ],
   "id": "d068f9c24df3264f",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### train",
   "id": "fcd5706ba9ffca25"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "df = pd.read_csv(LABEL_TRAIN_PATH)\n",
    "\n",
    "if DEBUG:\n",
    "    df = df.head(300)\n",
    "\n",
    "df['path'] = df['filename'].apply(lambda x: os.path.join(TRAIN_CROP_DATASET_DIR, x))\n",
    "\n",
    "skf = StratifiedKFold(n_splits=N_SPLITS, shuffle=True, random_state=SEED)\n",
    "folds = []\n",
    "for train_index, val_index in skf.split(df, df['METS']):\n",
    "    train_df = df.iloc[train_index]\n",
    "    val_df = df.iloc[val_index]\n",
    "    folds.append((train_df, val_df))"
   ],
   "id": "8472c316210ca9d1",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "for fold in range(5):\n",
    "    target_data = folds[fold]\n",
    "    train_df = target_data[0]\n",
    "    val_df = target_data[1]\n",
    "\n",
    "    data_module = PupilDataModule(\n",
    "        train_df,\n",
    "        val_df,\n",
    "        None,\n",
    "        batch_size=BATCH_SIZE,\n",
    "        num_workers=NUM_WORKERS,\n",
    "        img_size=IMG_SIZE,\n",
    "    )\n",
    "\n",
    "    model = PupilModel(\n",
    "        model_name=MODEL_NAME,\n",
    "        pretrained=True,\n",
    "        num_classes=9,\n",
    "        learning_rate=LEARNING_RATE\n",
    "    )\n",
    "\n",
    "    checkpoint_callback = ModelCheckpoint(\n",
    "        monitor='val_acc',\n",
    "        dirpath='checkpoints',\n",
    "        filename=f'fold_{fold}-' + '{epoch:02d}-{val_acc:.3f}',\n",
    "        save_top_k=1,\n",
    "        mode='max',\n",
    "    )\n",
    "\n",
    "    notebook_path = os.path.abspath('')\n",
    "    run_name = os.path.basename(notebook_path)\n",
    "    wandb.finish()\n",
    "    wandb_logger = WandbLogger(project=\"ganka_ai_2024\", name=f\"{run_name}_seed_{SEED}_fold_{fold}\")\n",
    "\n",
    "    trainer = pl.Trainer(\n",
    "        max_epochs=MAX_EPOCH,\n",
    "        accelerator=\"gpu\",\n",
    "        devices=1,\n",
    "        callbacks=[checkpoint_callback],\n",
    "        log_every_n_steps=10,\n",
    "        num_sanity_val_steps=0,\n",
    "        logger=wandb_logger,\n",
    "        deterministic=True\n",
    "    )\n",
    "\n",
    "    trainer.fit(model, datamodule=data_module)\n",
    "    wandb_logger.finalize(\"success\")\n",
    "    wandb.finish()\n",
    "\n",
    "    final_model_path = f'./checkpoints/final_model_seed_{SEED}_fold_{fold}.pth'\n",
    "    trainer.save_checkpoint(final_model_path)\n",
    "    print(f\"fold {fold} Final model saved at: {final_model_path}\")"
   ],
   "id": "5c4b1f0b5b57c441",
   "outputs": [],
   "execution_count": null
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
